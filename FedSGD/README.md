## Federated Stochastic Gradient Descent (SGD) 

Experiments with the Federated Accelerated SGD algorithm (FedAc), which is built on the principles of the Federated Average SGD algorithm (FedAvg). FedAc was published fairly recently [1] and sparked my interest when looking into optimized federated learning with deep neural networks. 

### References

1. [[2006.08950] Federated Accelerated Stochastic Gradient Descent](https://arxiv.org/abs/2006.08950)

